{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_Regression_Analysis",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparrow0hawk/pyspark_colab/blob/master/PySpark_Regression_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8U3BtmhtRx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Running Pyspark in Colab**\n",
        "\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab. One important note is that if you are new in Spark, it is better to avoid Spark 2.4.0 version since some people have already complained about its compatibility issue with python. \n",
        "Follow the steps to install the dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILheUROOhprv",
        "colab_type": "text"
      },
      "source": [
        "Now that you installed Spark and Java in Colab, it is time to set the environment path which enables you to run Pyspark in your Colab environment. Set the location of Java and Spark by running the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1b8k_OVf2QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwrqMk3HiMiE",
        "colab_type": "text"
      },
      "source": [
        "Run a local spark session to test your installation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Uz1NL4gHFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj8RCur28sRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "f120d3ef-a61f-4bf5-9c7b-45225e6df161"
      },
      "source": [
        "spark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://266568aa9208:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5f9b29cc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaQEt-8CLZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark.stop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LdZu2ny8rad",
        "colab_type": "text"
      },
      "source": [
        "## Big data concepts in Python\n",
        "\n",
        "filter(), map(), reduce() built in python functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h624C01388Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c42efad-d556-49d5-b082-433e196dcedd"
      },
      "source": [
        "x = ['hello','world','this','is','python','!']\n",
        "\n",
        "print(list(filter(lambda arg: len(arg) <= 4, x)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da7iOm069mSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0be33cdc-3c46-43da-8f77-dccb5cd755e3"
      },
      "source": [
        "# returns an iterable \n",
        "filter(lambda arg: len(arg) <= 4, x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<filter at 0x7f5f9a22c080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-KNjYa_95iK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "d4f263a6-95a0-42ec-f852-65f73fb44998"
      },
      "source": [
        "help(filter)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class filter in module builtins:\n",
            "\n",
            "class filter(object)\n",
            " |  filter(function or None, iterable) --> filter object\n",
            " |  \n",
            " |  Return an iterator yielding those items of iterable for which function(item)\n",
            " |  is true. If function is None, return the items that are true.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  __next__(self, /)\n",
            " |      Implement next(self).\n",
            " |  \n",
            " |  __reduce__(...)\n",
            " |      Return state information for pickling.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iiCeEAS9_4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dd614d6-c62a-4312-aa6c-3799adbb7fbb"
      },
      "source": [
        "# map the lambda function to every item in the list\n",
        "print(list(map(lambda arg: arg.upper(), x)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['HELLO', 'WORLD', 'THIS', 'IS', 'PYTHON', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYLkSA7j-b3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0bc1b9d-4c89-4d80-a851-231cfa2483a2"
      },
      "source": [
        "# this also returns an iterable\n",
        "map(lambda arg: arg.upper(), x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7f5f9a28b8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9LGueTp-j9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73491897-de51-43ed-fcb5-35cc3b1e93db"
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "print(reduce(lambda val1, val2: val1 + val2, x))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "helloworldthisispython!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_uzWfsL_hfM",
        "colab_type": "text"
      },
      "source": [
        "# Basic spark stuff\n",
        "\n",
        "From this [Real Python](https://realpython.com/pyspark-intro/#big-data-concepts-in-python) tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVD_bMnLBD0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "215fe44e-2e12-4d02-9b0f-3a86975b1cce"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/python/cpython/946b29ea0b3b386ed05e87e60b8617c9dc19cd53/Doc/copyright.rst"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-04 20:27:33--  https://raw.githubusercontent.com/python/cpython/946b29ea0b3b386ed05e87e60b8617c9dc19cd53/Doc/copyright.rst\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 451 [text/plain]\n",
            "Saving to: ‘copyright.rst’\n",
            "\n",
            "\rcopyright.rst         0%[                    ]       0  --.-KB/s               \rcopyright.rst       100%[===================>]     451  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-04 20:27:34 (21.1 MB/s) - ‘copyright.rst’ saved [451/451]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kSV4M6AAAD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b352b430-6037-48d5-d142-8fc26d5c3fa5"
      },
      "source": [
        "import pyspark\n",
        "\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "\n",
        "txt = sc.textFile('copyright.rst')\n",
        "print(txt.count())\n",
        "\n",
        "python_lines = txt.filter(lambda line: 'python' in line.lower())\n",
        "\n",
        "print(python_lines.count())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCeiv_eFFHTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ec7d506-524e-413e-bb31-ab6a2097ff47"
      },
      "source": [
        "# creating RDDs\n",
        "\n",
        "big_list = range(1000)\n",
        "rdd = sc.parallelize(big_list, numSlices=2)\n",
        "odds = rdd.filter(lambda x: x % 2 != 0)\n",
        "# .take() works like head\n",
        "odds.take(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 5, 7, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEb4HTRwiaJx",
        "colab_type": "text"
      },
      "source": [
        "Congrats! Your Colab is ready to run Pyspark. Let's build a simple Linear Regression model.\n",
        "\n",
        "# Linear Regression Model\n",
        "\n",
        "\n",
        "Linear Regression model is one the oldest and widely used machine learning approach which assumes a relationship between dependent and independent variables. For example, a modeler might want to predict the forecast of the rain based on the humidity ratio. Linear Regression consists of the best fitting line through the scattered points on the graph and the best fitting line is known as the regression line.\n",
        "\n",
        "The goal of this exercise to predict the housing prices by the given features. Let's predict the prices of the Boston Housing dataset by considering MEDV as the output variable and all the other variables as input.\n",
        "\n",
        "Download the dataset from [here](https://github.com/asifahmed90/pyspark-ML-in-Colab/blob/master/BostonHousing.csv) and keep it somewhere on your computer. Load the dataset into your Colab directory from your local system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAISFqHXf7dt",
        "colab_type": "code",
        "outputId": "93e509f5-b490-4719-b652-25d97a1bd846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/asifahmed90/pyspark-ML-in-Colab/master/BostonHousing.csv"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-04 21:10:37--  https://raw.githubusercontent.com/asifahmed90/pyspark-ML-in-Colab/master/BostonHousing.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35735 (35K) [text/plain]\n",
            "Saving to: ‘BostonHousing.csv’\n",
            "\n",
            "\rBostonHousing.csv     0%[                    ]       0  --.-KB/s               \rBostonHousing.csv   100%[===================>]  34.90K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-06-04 21:10:37 (2.46 MB/s) - ‘BostonHousing.csv’ saved [35735/35735]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNsM_jHqrjBg",
        "colab_type": "text"
      },
      "source": [
        "Check the dataset is uploaded correctly in the system by the following command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHU6cY5JLA3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a5fd5847-5b86-4896-95a8-12b3a91d7e2e"
      },
      "source": [
        "! head -n 10 BostonHousing.csv"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"crim\",\"zn\",\"indus\",\"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"b\",\"lstat\",\"medv\"\n",
            "0.00632,18,2.31,\"0\",0.538,6.575,65.2,4.09,1,296,15.3,396.9,4.98,24\n",
            "0.02731,0,7.07,\"0\",0.469,6.421,78.9,4.9671,2,242,17.8,396.9,9.14,21.6\n",
            "0.02729,0,7.07,\"0\",0.469,7.185,61.1,4.9671,2,242,17.8,392.83,4.03,34.7\n",
            "0.03237,0,2.18,\"0\",0.458,6.998,45.8,6.0622,3,222,18.7,394.63,2.94,33.4\n",
            "0.06905,0,2.18,\"0\",0.458,7.147,54.2,6.0622,3,222,18.7,396.9,5.33,36.2\n",
            "0.02985,0,2.18,\"0\",0.458,6.43,58.7,6.0622,3,222,18.7,394.12,5.21,28.7\n",
            "0.08829,12.5,7.87,\"0\",0.524,6.012,66.6,5.5605,5,311,15.2,395.6,12.43,22.9\n",
            "0.14455,12.5,7.87,\"0\",0.524,6.172,96.1,5.9505,5,311,15.2,396.9,19.15,27.1\n",
            "0.21124,12.5,7.87,\"0\",0.524,5.631,100,6.0821,5,311,15.2,386.63,29.93,16.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m606eNuQgA82",
        "colab_type": "code",
        "outputId": "2dc83791-4185-42a2-b7bd-277588a21ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BostonHousing.csv  sample_data\t\t      spark-2.4.5-bin-hadoop2.7.tgz\n",
            "copyright.rst\t   spark-2.4.5-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21D9EANUvnwF",
        "colab_type": "text"
      },
      "source": [
        "Now that we have uploaded the dataset, we can start analyzing. \n",
        "For our linear regression model we need to import two modules from Pyspark i.e. Vector Assembler and Linear Regression. Vector Assembler is a transformer that assembles all the features into one vector from multiple columns that contain type double. We could have used StringIndexer if any of our columns contains string values to convert it into numeric values. Luckily, the BostonHousing dataset only contains double values, so we don't need to worry about StringIndexer for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZeJ7WQCgM8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "dataset = spark.read.csv('BostonHousing.csv',inferSchema=True, header =True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_VcT_EQ9hOd",
        "colab_type": "code",
        "outputId": "00b3e402-dcca-49ea-a40a-6bcdbc449ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(crim=0.00632, zn=18.0, indus=2.31, chas=0, nox=0.538, rm=6.575, age=65.2, dis=4.09, rad=1, tax=296, ptratio=15.3, b=396.9, lstat=4.98, medv=24.0),\n",
              " Row(crim=0.02731, zn=0.0, indus=7.07, chas=0, nox=0.469, rm=6.421, age=78.9, dis=4.9671, rad=2, tax=242, ptratio=17.8, b=396.9, lstat=9.14, medv=21.6),\n",
              " Row(crim=0.02729, zn=0.0, indus=7.07, chas=0, nox=0.469, rm=7.185, age=61.1, dis=4.9671, rad=2, tax=242, ptratio=17.8, b=392.83, lstat=4.03, medv=34.7),\n",
              " Row(crim=0.03237, zn=0.0, indus=2.18, chas=0, nox=0.458, rm=6.998, age=45.8, dis=6.0622, rad=3, tax=222, ptratio=18.7, b=394.63, lstat=2.94, medv=33.4),\n",
              " Row(crim=0.06905, zn=0.0, indus=2.18, chas=0, nox=0.458, rm=7.147, age=54.2, dis=6.0622, rad=3, tax=222, ptratio=18.7, b=396.9, lstat=5.33, medv=36.2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJLoAfqVv8-E",
        "colab_type": "text"
      },
      "source": [
        "Notice that we used InferSchema inside read.csv mofule. InferSchema enables us to infer automatically different data types for each column.\n",
        "\n",
        "Let us print look into the dataset to see the data types of each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gok1FXWugYkE",
        "colab_type": "code",
        "outputId": "2a51888a-9680-4b16-80fd-c2582d61c73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "dataset.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- crim: double (nullable = true)\n",
            " |-- zn: double (nullable = true)\n",
            " |-- indus: double (nullable = true)\n",
            " |-- chas: integer (nullable = true)\n",
            " |-- nox: double (nullable = true)\n",
            " |-- rm: double (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- dis: double (nullable = true)\n",
            " |-- rad: integer (nullable = true)\n",
            " |-- tax: integer (nullable = true)\n",
            " |-- ptratio: double (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- lstat: double (nullable = true)\n",
            " |-- medv: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L9VJqsHwEGf",
        "colab_type": "text"
      },
      "source": [
        "Next step is to convert all the features from different columns into a single column and let's call this new vector column as 'Attributes' in the outputCol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKSqdT9QgkfD",
        "colab_type": "code",
        "outputId": "42d0ea22-3bb1-4986-e70b-e1cfe852487b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "#Input all the features in one vector column\n",
        "assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', \n",
        "                                       'chas', 'nox', 'rm', \n",
        "                                       'age', 'dis', 'rad', \n",
        "                                       'tax', 'ptratio', 'b', \n",
        "                                       'lstat'], \n",
        "                            outputCol = 'Attributes')\n",
        "\n",
        "output = assembler.transform(dataset)\n",
        "\n",
        "#Input vs Output\n",
        "finalized_data = output.select(\"Attributes\",\"medv\")\n",
        "\n",
        "finalized_data.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|          Attributes|medv|\n",
            "+--------------------+----+\n",
            "|[0.00632,18.0,2.3...|24.0|\n",
            "|[0.02731,0.0,7.07...|21.6|\n",
            "|[0.02729,0.0,7.07...|34.7|\n",
            "|[0.03237,0.0,2.18...|33.4|\n",
            "|[0.06905,0.0,2.18...|36.2|\n",
            "|[0.02985,0.0,2.18...|28.7|\n",
            "|[0.08829,12.5,7.8...|22.9|\n",
            "|[0.14455,12.5,7.8...|27.1|\n",
            "|[0.21124,12.5,7.8...|16.5|\n",
            "|[0.17004,12.5,7.8...|18.9|\n",
            "|[0.22489,12.5,7.8...|15.0|\n",
            "|[0.11747,12.5,7.8...|18.9|\n",
            "|[0.09378,12.5,7.8...|21.7|\n",
            "|[0.62976,0.0,8.14...|20.4|\n",
            "|[0.63796,0.0,8.14...|18.2|\n",
            "|[0.62739,0.0,8.14...|19.9|\n",
            "|[1.05393,0.0,8.14...|23.1|\n",
            "|[0.7842,0.0,8.14,...|17.5|\n",
            "|[0.80271,0.0,8.14...|20.2|\n",
            "|[0.7258,0.0,8.14,...|18.2|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNgFCto2wHLd",
        "colab_type": "text"
      },
      "source": [
        "Here, 'Attributes' are in the input features from all the columns and 'medv' is the target column.\n",
        "Next, we should split the training and testing data according to our dataset (0.8 and 0.2 in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwe1VT0UNOIN",
        "colab_type": "code",
        "outputId": "956613f7-a5a5-4748-cc75-4ab5b1feb015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "#Split training and testing data\n",
        "train_data,test_data = finalized_data.randomSplit([0.8,0.2])\n",
        "\n",
        "\n",
        "regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
        "\n",
        "#Learn to fit the model from training set\n",
        "regressor = regressor.fit(train_data)\n",
        "\n",
        "#To predict the prices on testing set\n",
        "pred = regressor.evaluate(test_data)\n",
        "\n",
        "#Predict the model\n",
        "pred.predictions.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+------------------+\n",
            "|          Attributes|medv|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[0.01301,35.0,1.5...|32.7| 30.07670363535312|\n",
            "|[0.01538,90.0,3.7...|44.0| 37.75244575519337|\n",
            "|[0.01778,95.0,1.4...|32.9|30.596108327253294|\n",
            "|[0.0187,85.0,4.15...|23.1|25.717620889129734|\n",
            "|[0.01965,80.0,1.7...|20.1|19.992379582220035|\n",
            "|[0.02729,0.0,7.07...|34.7|30.425294527192754|\n",
            "|[0.03113,0.0,4.39...|17.5|16.330496893793097|\n",
            "|[0.03237,0.0,2.18...|33.4|28.578543755284294|\n",
            "|[0.03306,0.0,5.19...|20.6| 22.16010760013387|\n",
            "|[0.03359,75.0,2.9...|34.9| 34.42265990782376|\n",
            "|[0.03537,34.0,6.0...|22.0|28.784081950984906|\n",
            "|[0.03584,80.0,3.3...|23.5| 30.77179427151925|\n",
            "|[0.03738,0.0,5.19...|20.7| 21.65956978285279|\n",
            "|[0.04297,52.5,5.3...|24.8|26.706348196385573|\n",
            "|[0.0456,0.0,13.89...|23.3|26.369847201011538|\n",
            "|[0.04684,0.0,3.41...|22.6|26.949731074397704|\n",
            "|[0.04981,21.0,5.6...|23.4| 23.90871028835852|\n",
            "|[0.05372,0.0,13.9...|27.1|27.156639422924407|\n",
            "|[0.05425,0.0,4.05...|24.6| 29.54769429196901|\n",
            "|[0.06466,70.0,2.2...|22.5|29.459287514682245|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vYyp5dwOm_",
        "colab_type": "text"
      },
      "source": [
        "We can also print the coefficient and intercept of the regression model by using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eja1BLiaTThT",
        "colab_type": "code",
        "outputId": "ebaaeadc-ac17-4e59-a494-62810e1e9438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#coefficient of the regression model\n",
        "coeff = regressor.coefficients\n",
        "\n",
        "#X and Y intercept\n",
        "intr = regressor.intercept\n",
        "\n",
        "print (\"The coefficient of the model is : %a\" %coeff)\n",
        "print (\"The Intercept of the model is : %f\" %intr)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The coefficient of the model is : DenseVector([-0.1239, 0.056, 0.0205, 2.7283, -16.8634, 3.218, 0.0163, -1.4331, 0.3657, -0.0134, -0.9328, 0.0096, -0.6229])\n",
            "The Intercept of the model is : 39.049826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYORz3Q9wTSW",
        "colab_type": "text"
      },
      "source": [
        "# Basic Statistical Analysis\n",
        "\n",
        "Once we are done with the basic linear regression operation, we can go a bit further and analyze our model statistically by importing RegressionEvaluator module from Pyspark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qrQdEj62ptt",
        "colab_type": "code",
        "outputId": "94ff1f60-0678-4942-a07e-e3173ea50602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.703\n",
            "MSE: 22.118\n",
            "MAE: 3.457\n",
            "r2: 0.738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxg6CW4OzrrH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}